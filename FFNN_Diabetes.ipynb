{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/The-Complete-Neural-Networks-Bootcamp-Theory-Applications/blob/master/FFNN_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkJ6euQ_SUBm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT5zePE0SUBr"
      },
      "outputs": [],
      "source": [
        "# Load the dataset using Pandas\n",
        "data = pd.read_csv('/content/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0cqQSr1SUBs"
      },
      "outputs": [],
      "source": [
        "# For x: Extract out the dataset from all the rows (all samples) and all columns except last column (all features).\n",
        "# For y: Extract out the last column (which is the label)\n",
        "# Convert both to numpy using the .values method\n",
        "x = data.iloc[:,0:-1].values\n",
        "y_string= list(data.iloc[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1BnyOLeSUBt",
        "outputId": "ffd69766-5561-4c80-c3c1-837c0eb0d7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.  148.   72.   35.    0.   33.6  50. ]\n",
            " [  1.   85.   66.   29.    0.   26.6  31. ]\n",
            " [  8.  183.   64.    0.    0.   23.3  32. ]]\n",
            "['positive', 'negative', 'positive']\n"
          ]
        }
      ],
      "source": [
        "# Lets have a look some samples from our data\n",
        "print(x[:3])\n",
        "print(y_string[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0dhDUIRSUBu"
      },
      "outputs": [],
      "source": [
        "# Our neural network only understand numbers! So convert the string to labels\n",
        "y_int = []\n",
        "for string in y_string:\n",
        "    if string == 'positive':\n",
        "        y_int.append(1)\n",
        "    else:\n",
        "        y_int.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "haMx0yPCU0d8",
        "outputId": "b9b3d5da-bf6f-4b85-f345-0bffddd6b51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Number of times pregnant  Plasma glucose concentration  \\\n",
              "0                         6                           148   \n",
              "1                         1                            85   \n",
              "2                         8                           183   \n",
              "3                         1                            89   \n",
              "4                         0                           137   \n",
              "\n",
              "   Diastolic blood pressure  Triceps skin fold thickness  \\\n",
              "0                        72                           35   \n",
              "1                        66                           29   \n",
              "2                        64                            0   \n",
              "3                        66                           23   \n",
              "4                        40                           35   \n",
              "\n",
              "   2-Hour serum insulin  Body mass index  Age     Class  \n",
              "0                     0             33.6   50  positive  \n",
              "1                     0             26.6   31  negative  \n",
              "2                     0             23.3   32  positive  \n",
              "3                    94             28.1   21  negative  \n",
              "4                   168             43.1   33  positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bf7964d-e466-4fda-990f-117cad9cb5b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of times pregnant</th>\n",
              "      <th>Plasma glucose concentration</th>\n",
              "      <th>Diastolic blood pressure</th>\n",
              "      <th>Triceps skin fold thickness</th>\n",
              "      <th>2-Hour serum insulin</th>\n",
              "      <th>Body mass index</th>\n",
              "      <th>Age</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>50</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>31</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>32</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>21</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>33</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bf7964d-e466-4fda-990f-117cad9cb5b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bf7964d-e466-4fda-990f-117cad9cb5b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bf7964d-e466-4fda-990f-117cad9cb5b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f069855d-6c67-43b6-8c3b-2b929bd33bff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f069855d-6c67-43b6-8c3b-2b929bd33bff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f069855d-6c67-43b6-8c3b-2b929bd33bff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Number of times pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Plasma glucose concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diastolic blood pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Triceps skin fold thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2-Hour serum insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body mass index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.884160320375446,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOLsO9faSUBv"
      },
      "outputs": [],
      "source": [
        "# Now convert to an array\n",
        "y = np.array(y_int, dtype = 'float64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYhudMmBSUBv"
      },
      "source": [
        "### $x^{\\prime}=\\frac{x-\\mu}{\\sigma}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyBHPgr0SUBx"
      },
      "outputs": [],
      "source": [
        "# Feature Normalization. All features should have the same range of values (-1,1)\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj1Q4VYySUBy"
      },
      "outputs": [],
      "source": [
        "# Now we convert the arrays to PyTorch tensors\n",
        "x = torch.tensor(x)\n",
        "# We add an extra dimension to convert this array to 2D\n",
        "y = torch.tensor(y).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Pytorch Tensors\n",
        "First, torch.tensor(y) converts y to a PyTorch tensor.\n",
        "\n",
        "The unsqueeze(1) method adds an extra dimension to the tensor at the specified position (in this case, position 1).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Why Add an Extra Dimension?\n",
        "Adding an extra dimension is often necessary for data compatibility with various neural network layers or operations.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Original Shape of y:\n",
        "If y is a 1D tensor (e.g., [1, 2, 3]),\n",
        "its shape would be (3,).\n",
        "\n",
        "---\n",
        "# Shape After unsqueeze(1):\n",
        "Adding an extra dimension at position 1 converts y to a 2D tensor. For example:\n",
        "\n",
        "Original tensor: [1, 2, 3] with shape (3,)\n",
        "\n",
        "After unsqueeze(1): [[1], [2], [3]] with shape (3, 1)\n",
        "\n",
        "This reshaping is often required for:\n",
        "\n",
        "##Batch Processing\n",
        "\n",
        "Neural network operations expect inputs to have a certain number of dimensions. For instance, many operations expect a batch of inputs, where each input is a row in a 2D tensor.\n",
        "\n",
        "##Compatibility with Layers\n",
        "\n",
        "Certain layers (like fully connected layers) expect inputs in a 2D format where one dimension is the batch size and the other is the feature size."
      ],
      "metadata": {
        "id": "321f0l95W6_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCYNKFIGSUBz",
        "outputId": "d5828691-c9a8-4b91-f38a-8c183117e5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768, 7])\n",
            "torch.Size([768, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwOeKxnfSUBz"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self,x,y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        # Get one item from the dataset\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset class in PyTorch\n",
        "\n",
        "is useful for several reasons, particularly when working with datasets that don’t fit neatly into the pre-defined formats provided by PyTorch’s built-in datasets. Here’s why you might create such a class:\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 1. Custom Data Handling\n",
        "##Different Data Formats\n",
        "\n",
        "If your data isn't already in a format that PyTorch can easily consume (like a CSV file, JSON, or a non-standard data structure), you can use a custom dataset class to handle loading, parsing, and transforming the data as needed.\n",
        "\n",
        "##Complex Data Loading\n",
        "\n",
        "For more complex data sources, like images stored in directories or data split across multiple files, a custom dataset class allows you to define how data is accessed and processed.\n",
        "\n",
        "-----\n",
        "\n",
        "# 2. Integration with PyTorch Utilities\n",
        "##DataLoader Compatibility\n",
        "\n",
        "By subclassing torch.utils.data.Dataset, your dataset can be used with PyTorch’s DataLoader, which handles batching, shuffling, and parallel data loading.\n",
        "\n",
        "This integration simplifies the process of preparing data for training and evaluation.\n",
        "\n",
        "-----\n",
        "##Transformation and Augmentation\n",
        "\n",
        "You can easily add data transformations and augmentations within your custom dataset class.\n",
        "\n",
        "For example, you might include data normalization, resizing, or other preprocessing steps directly in your dataset class.\n",
        "\n",
        "-----\n",
        "\n",
        "#3. Flexibility and Reusability\n",
        "##Custom Operations\n",
        "\n",
        "If your dataset requires specific operations or preprocessing steps, such as scaling values, splitting sequences, or applying domain-specific transformations, these can be incorporated directly into your dataset class.\n",
        "\n",
        "##Reuse\n",
        "\n",
        "Once created, a custom dataset class can be reused across different projects or experiments, ensuring consistency and reducing the need for repetitive code.\n",
        "\n",
        "-------\n",
        "\n",
        "#4. Simplified Code Management\n",
        "##Encapsulation\n",
        "\n",
        "The dataset class encapsulates all the data-related functionality in one place, making your code cleaner and easier to maintain.\n",
        "\n",
        "##Clarity\n",
        "\n",
        "Having a well-defined dataset class helps in clearly defining the data pipeline, which is beneficial for both debugging and collaborative work.\n",
        "\n",
        "-----\n",
        "----\n",
        "\n",
        "#Custom CSV Loading\n",
        "\n",
        "##1. Class Definition\n",
        "\n",
        "    class Dataset(Dataset):\n",
        "\n",
        "The Dataset class inherits from torch.utils.data.Dataset, which is an abstract class that PyTorch provides for creating custom datasets.\n",
        "\n",
        "The custom class Dataset here overrides the necessary methods to define how to access and manage the dataset.\n",
        "\n",
        "-----\n",
        "##2. Initialization Method\n",
        "\n",
        "    def __init__(self, x, y):\n",
        "       self.x = x\n",
        "       self.y = y\n",
        "\n",
        "The __init__ method is the constructor for the Dataset class.\n",
        "\n",
        "It initializes the dataset object with x and y, which are typically the features and labels of the dataset, respectively.\n",
        "self.x and self.y store the data and labels for the dataset.\n",
        "\n",
        "----\n",
        "##3. Getting an Item\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "       # Get one item from the dataset\n",
        "       return self.x[index], self.y[index]\n",
        "\n",
        "The __getitem__ method retrieves a data point and its corresponding label from the dataset given an index.\n",
        "\n",
        "This method allows you to use indexing on an instance of this dataset class, e.g., dataset[index], to get the item at that position in x and its corresponding label in y.\n",
        "\n",
        "----\n",
        "##4. Dataset Length\n",
        "\n",
        "    def __len__(self):\n",
        "       return len(self.x)\n",
        "\n",
        "The __len__ method returns the total number of items in the dataset.\n",
        "\n",
        "It uses the length of self.x because x and y are expected to have the same length. This ensures that the dataset provides a correct size when queried.\n",
        "\n",
        "----\n",
        "##How to Use This Dataset Class\n",
        "Here’s how you can use this custom Dataset class with PyTorch’s DataLoader:\n",
        "\n",
        "    import torch\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "-----\n",
        "# Example data\n",
        "    x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])  # Example features\n",
        "    y = torch.tensor([0, 1, 0, 1])  # Example labels\n",
        "\n",
        "# Instantiate the custom dataset\n",
        "dataset = Dataset(x, y)\n",
        "\n",
        "# Create a DataLoader for batching, shuffling, etc.\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Iterate over the DataLoader\n",
        "for batch_x, batch_y in dataloader:\n",
        "    print('Batch X:', batch_x)\n",
        "    print('Batch Y:', batch_y)\n",
        "\n",
        "----------\n",
        "#Summary\n",
        "__init__: Initializes the dataset with features x and labels y.\n",
        "\n",
        "__getitem__: Returns the feature and label at a specified index.\n",
        "\n",
        "__len__: Returns the number of items in the dataset.\n",
        "\n",
        "This custom dataset class allows you to integrate your data with PyTorch’s data loading utilities seamlessly, enabling you to leverage batching, shuffling, and other data management features provided by DataLoader.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xk7qxc_gY1J9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-H--FEkSUB0",
        "outputId": "840e3794-f0b3-4a9e-ea04-278226072e25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzuKRdwlSUB0"
      },
      "outputs": [],
      "source": [
        "# Load the data to your dataloader for batch processing and shuffling\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data to your dataloader for batch processing and shuffling\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##torch.utils.data.DataLoader\n",
        "\n",
        "This is a utility provided by PyTorch to create an iterable over your dataset. It allows you to load data in batches, shuffle the data, and use multiprocessing for faster data loading.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##dataset\n",
        "\n",
        "This is the dataset object you have created (usually an instance of a class derived from torch.utils.data.Dataset).\n",
        "\n",
        "It contains the data samples and their corresponding labels.\n",
        "\n",
        "----\n",
        "##batch_size=32\n",
        "\n",
        "This parameter specifies the number of samples to load in each batch.\n",
        "\n",
        "In this case, the DataLoader will load 32 samples at a time.\n",
        "\n",
        "-----\n",
        "\n",
        "##shuffle=True\n",
        "\n",
        "This parameter ensures that the data is shuffled at the beginning of each epoch.\n",
        "\n",
        " Shuffling the data is important to prevent the model from learning the order of the samples and to improve generalization.\n",
        "\n",
        " ----\n",
        "Summary\n",
        "\n",
        " The DataLoader is an essential tool in PyTorch for managing datasets, providing an efficient way to load data in batches, shuffle it, and perform preprocessing on the fly.\n",
        "\n",
        " It abstracts much of the complexity involved in handling data, allowing you to focus on building and training your models."
      ],
      "metadata": {
        "id": "PK4woqXYg_cg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ElFFg43SUB1",
        "outputId": "67b9ecf0-9790-40fd-8d62-263c6ad64112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 24 batches in the dataset\n",
            "For one iteration (batch), there is:\n",
            "Data:    torch.Size([32, 7])\n",
            "Labels:  torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "# Let's have a look at the data loader\n",
        "print(\"There is {} batches in the dataset\".format(len(train_loader)))\n",
        "for (x,y) in train_loader:\n",
        "    print(\"For one iteration (batch), there is:\")\n",
        "    print(\"Data:    {}\".format(x.shape))\n",
        "    print(\"Labels:  {}\".format(y.shape))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMYrZkMTSUB1"
      },
      "source": [
        "![demo](https://user-images.githubusercontent.com/30661597/60379583-246e5e80-9a68-11e9-8b7f-a4294234c201.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kqXD93ESUB1"
      },
      "outputs": [],
      "source": [
        "# Now let's build the above network\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_features, 5)\n",
        "        self.fc2 = nn.Linear(5, 4)\n",
        "        self.fc3 = nn.Linear(4, 3)\n",
        "        self.fc4 = nn.Linear(3, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Necessary Libraries\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "\n",
        "These imports bring in PyTorch's core tensor library (torch) and neural network module (torch.nn), which provides a variety of classes and functions to create neural networks.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Defining the Model Class\n",
        "\n",
        "    class Model(nn.Module):\n",
        "\n",
        "This line defines a new class named Model that inherits from nn.Module, which is the base class for all neural network modules in PyTorch.\n",
        "\n",
        "Inheriting from nn.Module provides a lot of built-in functionality for handling model parameters, gradients, and more.\n",
        "\n",
        "----\n",
        "#Initializing the Model\n",
        "\n",
        "    def __init__(self, input_features):\n",
        "       super(Model, self).__init__()\n",
        "\n",
        "The __init__ method initializes the model. super(Model, self).__init__() ensures that the base class (nn.Module) is properly initialized.\n",
        "\n",
        "self.fc1 to self.fc4 are fully connected (linear) layers. Each layer transforms the input features to the output features.\n",
        "\n",
        "These lines define the layers and activation functions of the neural network:\n",
        "\n",
        "#Defining the Layers\n",
        "\n",
        "    self.fc1 = nn.Linear(input_features, 5)\n",
        "\n",
        "self.fc1 to self.fc4 are fully connected (linear) layers. Each layer transforms the input features to the output features.\n",
        "\n",
        "self.fc1 takes input_features and maps them to 5 features.\n",
        "\n",
        "    self.fc2 = nn.Linear(5, 4)\n",
        "\n",
        "self.fc1 to self.fc4 are fully connected (linear) layers. Each layer transforms the input features to the output features.\n",
        "\n",
        "    self.fc3 = nn.Linear(4, 3)\n",
        "\n",
        "self.fc3 takes the 4 features from self.fc2 and maps them to 3 features.\n",
        "\n",
        "    self.fc4 = nn.Linear(3, 1)\n",
        "\n",
        "self.fc4 takes the 3 features from self.fc3 and maps them to 1 feature.\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "self.sigmoid is a sigmoid activation function.\n",
        "\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "self.tanh is a hyperbolic tangent activation function.\n",
        "\n",
        "-----\n",
        "##Defining the Forward Pass\n",
        "\n",
        "    def forward(self, x):\n",
        "       out = self.fc1(x)\n",
        "       out = self.tanh(out)\n",
        "       out = self.fc2(out)\n",
        "       out = self.tanh(out)\n",
        "       out = self.fc3(out)\n",
        "       out = self.tanh(out)\n",
        "       out = self.fc4(out)\n",
        "       out = self.sigmoid(out)\n",
        "       return out\n",
        "\n",
        "The forward method defines how the input tensor x passes through the network layers and activation functions.\n",
        "\n",
        "This method is automatically called when you perform a forward pass on the network, e.g., model(x).\n",
        "\n",
        "-----\n",
        "##First Layer\n",
        "\n",
        "    out = self.fc1(x)\n",
        "    \n",
        "The input x is passed through the first linear layer.\n",
        "\n",
        "    out = self.tanh(out)\n",
        "    \n",
        "The output of the first linear layer is passed through the tanh activation function.\n",
        "\n",
        "---\n",
        "##Second Layer\n",
        "\n",
        "    out = self.fc2(out)\n",
        "\n",
        "The result from the previous step is passed through the second linear layer.\n",
        "\n",
        "    out = self.tanh(out)\n",
        "\n",
        "The output of the second linear layer is passed through the tanh activation function.\n",
        "\n",
        "-----\n",
        "##Third Layer\n",
        "\n",
        "    out = self.fc3(out)\n",
        "\n",
        "The result from the previous step is passed through the third linear layer.\n",
        "\n",
        "    out = self.tanh(out)\n",
        "\n",
        "The output of the third linear layer is passed through the tanh activation function.\n",
        "\n",
        "-----\n",
        "##Fourth Layer\n",
        "\n",
        "    out = self.fc4(out)\n",
        "\n",
        "The result from the previous step is passed through the fourth linear layer.\n",
        "\n",
        "    out = self.sigmoid(out)\n",
        "\n",
        "The output of the fourth linear layer is passed through the sigmoid activation function.\n",
        "\n",
        "----\n",
        "##Return Output\n",
        "\n",
        "The final output out is returned.\n",
        "\n",
        "----\n",
        "#Summary\n",
        "This neural network model performs a sequence of linear transformations followed by non-linear activation functions (tanh and sigmoid).\n",
        "\n",
        "It takes an input tensor, passes it through four linear layers, applies tanh activations after the first three layers, and a sigmoid activation after the last layer.\n",
        "\n",
        "This kind of architecture is commonly used for binary classification tasks, where the final sigmoid activation ensures the output is between 0 and 1, representing a probability."
      ],
      "metadata": {
        "id": "kWrUu_AuQUG-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAQadaddSUB1"
      },
      "source": [
        "$H_{p}(q)=-\\frac{1}{N} \\sum_{i=1}^{N} y_{i} \\cdot \\log \\left(p\\left(y_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\cdot \\log \\left(1-p\\left(y_{i}\\right)\\right)$\n",
        "\n",
        "\n",
        "cost = -(Y * torch.log(hypothesis) + (1 - Y) * torch.log(1 - hypothesis)).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the network (an object of the Net class)\n",
        "net = Model(x.shape[1])\n",
        "\n",
        "# In Binary Cross Entropy: the input and output should have the same shape\n",
        "# size_average = True is deprecated, use reduction='mean' instead\n",
        "criterion = torch.nn.BCELoss(reduction='mean')\n",
        "\n",
        "# We will use SGD with momentum with a learning rate of 0.1\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "uQBDYqSYbh_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the network (an object of the Net class)\n",
        "    net = Model(x.shape[1])\n",
        "\n",
        "##Model(x.shape[1])\n",
        "\n",
        "This initializes an instance of the Model class. The Model class is assumed to be defined elsewhere and should inherit from torch.nn.Module.\n",
        "\n",
        "##x.shape[1]\n",
        "\n",
        "This gets the number of input features. If x is a 2D tensor representing your dataset, x.shape[1] gives the number of features (columns) in your data.\n",
        "\n",
        "When we initialize our model, we need to tell it how many input features it should expect.\n",
        "\n",
        "This is crucial because the input layer of the model must match the number of features in the dataset.\n",
        "\n",
        "###x.shape[1]\n",
        "\n",
        "This extracts the number of features (columns) from x. If x.shape is (100, 3), then x.shape[1] is 3.\n",
        "\n",
        "###Model(x.shape[1])\n",
        "\n",
        "This initializes the Model class with 3 as the number of input features. The Model class uses this information to create the first layer of the neural network with the correct number of input nodes.\n",
        "\n",
        "##net\n",
        "\n",
        "This variable holds the created model, which will be used for training and predictions.\n",
        "\n",
        "-----\n",
        "##Defining the Loss Function\n",
        "\n",
        "###In Binary Cross Entropy: the input and output should have the same shape\n",
        "### size_average = True is deprecated, use reduction='mean' instead\n",
        "\n",
        "    criterion = torch.nn.BCELoss(reduction='mean')\n",
        "\n",
        "##torch.nn.BCELoss\n",
        "\n",
        "This is a built-in PyTorch loss function used for binary classification problems.\n",
        "\n",
        "BCELoss stands for Binary Cross Entropy Loss.\n",
        "\n",
        "    reduction='mean'\n",
        "\n",
        "This specifies that the loss will be averaged over the batch.\n",
        "\n",
        "The terms \"reduction\" and \"deprecation\" are used in different contexts in software development and mathematics. Here’s a detailed explanation of each:\n",
        "----\n",
        "----\n",
        "#1. Reduction\n",
        "In the context of loss functions in machine learning and deep learning, reduction refers to how the output of the loss function is aggregated or summarized.\n",
        "\n",
        "Specifically, it determines how to combine the individual loss values from a batch of examples into a single scalar value.\n",
        "\n",
        "###Common Reduction Methods:\n",
        "'none': No reduction is applied. The loss values for each element in the batch are returned as-is.\n",
        "\n",
        "This is useful when you need to perform custom operations on the individual losses.\n",
        "\n",
        "####'mean':\n",
        "\n",
        "The sum of the output is divided by the number of elements in the output. This method calculates the average loss per element, which is useful for getting a normalized measure of loss across the batch.\n",
        "\n",
        "####'sum'\n",
        "\n",
        "The output is summed. This aggregates all the loss values into a single value by summing them up.\n",
        "\n",
        "This method provides the total loss across all elements in the batch.\n",
        "\n",
        "###Example in PyTorch\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "\n",
        "# Create a loss function\n",
        "    criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Example predictions and target labels\n",
        "    outputs = torch.tensor([2.0, 3.0], dtype=torch.float32)\n",
        "    targets = torch.tensor([2.5, 2.5], dtype=torch.float32)\n",
        "\n",
        "# Compute the loss\n",
        "    loss = criterion(outputs, targets)\n",
        "    print(\"Mean Loss:\", loss.item())\n",
        "\n",
        "In this example, using reduction='mean' will average the loss values across all elements in the batch, while reduction='sum' would sum them.\n",
        "\n",
        "----\n",
        "#2. Deprecation\n",
        "Deprecation is a term used in software development to indicate that a feature, function, or method is considered obsolete and may be removed in future versions.\n",
        "\n",
        "Deprecated features are still available but are discouraged from being used because there are better or more efficient alternatives.\n",
        "\n",
        "##Why Features Get Deprecated:\n",
        "Improved Alternatives: Newer methods or functions are introduced that provide better performance or usability.\n",
        "\n",
        "Maintenance: Maintaining older features can be burdensome, and removing them can simplify the codebase and reduce potential bugs.\n",
        "\n",
        "Standardization: Aligning with best practices or industry standards.\n",
        "\n",
        "When a feature is deprecated, developers are typically encouraged to use the recommended alternatives. This helps in migrating to newer versions of a library or framework without relying on outdated features.\n",
        "\n",
        "##Example of Deprecation in PyTorch:\n",
        "\n",
        "In PyTorch, size_average=True was deprecated in favor of reduction='mean':\n",
        "\n",
        "###Deprecated: size_average=True was used to average the loss across all elements.\n",
        "\n",
        "###Updated:\n",
        "\n",
        "reduction='mean' is the new standard to achieve the same effect and provides more flexibility.\n",
        "\n",
        "Using deprecated features can lead to warnings or errors, and the feature might be removed entirely in future releases, so it is essential to update code to use the recommended practices.\n",
        "\n",
        "----\n",
        "##Summary\n",
        "Reduction specifies how to aggregate loss values (e.g., mean, sum, or none) and is crucial for understanding how to interpret the loss values produced by a loss function.\n",
        "\n",
        "Deprecation indicates that a feature is outdated and should be replaced with newer alternatives to ensure compatibility with future versions and better practices.\n",
        "\n",
        "-----\n",
        "-----\n",
        "The argument\n",
        "\n",
        "    size_average=True\n",
        "\n",
        " used to achieve this is now deprecated, and reduction='mean' is the recommended usage.\n",
        "\n",
        "-----------\n",
        "##Setting Up the Optimizer\n",
        "\n",
        "# We will use SGD with momentum with a learning rate of 0.1\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "##torch.optim.SGD\n",
        "\n",
        "This is a stochastic gradient descent optimizer provided by PyTorch.\n",
        "\n",
        "##net.parameters()\n",
        "\n",
        "This passes the parameters of the net model to the optimizer so that they can be updated during training.\n",
        "\n",
        "##lr=0.1\n",
        "\n",
        "This sets the learning rate for the optimizer to 0.1. The learning rate determines the step size at each iteration while moving toward a minimum of the loss function.\n",
        "\n",
        "##momentum=0.9\n",
        "\n",
        "This adds momentum to the gradient updates to accelerate convergence, especially in the relevant direction and dampen oscillations.\n",
        "\n",
        "-----\n",
        "#Summary\n",
        "Here’s a step-by-step summary of what each part does:\n",
        "\n",
        "##Model Initialization:\n",
        "\n",
        "An instance of the Model class is created with the number of input features passed as an argument.\n",
        "\n",
        "##Loss Function Definition:\n",
        "\n",
        "The loss function used for training is defined. In this case, it’s Binary Cross Entropy Loss, appropriate for binary classification tasks.\n",
        "Optimizer Setup:\n",
        "\n",
        "##The optimizer is set up to adjust the parameters of the model during training using Stochastic Gradient Descent with momentum.\n",
        "\n",
        "----\n",
        "----\n",
        "#Example Usage\n",
        "This setup is typically part of a larger workflow that includes data loading, forward and backward passes, and parameter updates. Here’s how it might fit into a training loop:\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "\n",
        "## Assuming the Model class and data (x, y) are already defined\n",
        "\n",
        "## Create the network\n",
        "    net = Model(x.shape[1])\n",
        "\n",
        "## Define the loss criterion\n",
        "    criterion = torch.nn.BCELoss(reduction='mean')\n",
        "\n",
        "## Set up the optimizer\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "-----\n",
        "# Example training loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:  # Assuming train_loader is defined\n",
        "           # Forward pass\n",
        "            outputs = net(inputs.float())\n",
        "            loss = criterion(outputs, labels.float())\n",
        "\n",
        "            # Backward pass and optimization\n",
        "              optimizer.zero_grad()  # Clear gradients\n",
        "              loss.backward()        # Compute gradients\n",
        "              optimizer.step()       # Update parameters\n",
        "\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "   print('Finished Training')\n",
        "\n",
        "\n",
        "In this example, train_loader would be a DataLoader object that provides batches of inputs and labels. The model's parameters are updated in each iteration of the loop to minimize the loss, improving the model's performance on the task."
      ],
      "metadata": {
        "id": "pwFh4gaub_QQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d2ZybGbSUB2"
      },
      "outputs": [],
      "source": [
        "# Train the network\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs,labels in train_loader:\n",
        "        inputs = inputs.float()\n",
        "        labels = labels.float()\n",
        "        # Feed Forward\n",
        "        output = net(inputs)\n",
        "        # Loss Calculation\n",
        "        loss = criterion(output, labels)\n",
        "        # Clear the gradient buffer (we don't want to accumulate gradients)\n",
        "        optimizer.zero_grad()\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # Weight Update: w <-- w - lr * gradient\n",
        "        optimizer.step()\n",
        "\n",
        "    #Accuracy\n",
        "    # Since we are using a sigmoid, we will need to perform some thresholding\n",
        "    output = (output>0.5).float()\n",
        "\n",
        "    # Accuracy: (output == labels).float().sum() / output.shape[0]\n",
        "    accuracy = (output == labels).float().mean()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate and print the loss and accuracy\n",
        "## Initialization:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### num_epochs = 200\n",
        "\n",
        "The number of times the entire training dataset will pass through the network.\n",
        "\n",
        "-----\n",
        "### train_loader\n",
        "\n",
        "A DataLoader object that provides batches of inputs and labels from the training dataset.\n",
        "\n",
        "-----\n",
        "###Training Loop\n",
        "\n",
        "###for epoch in range(num_epochs):\n",
        "\n",
        "Loop over the number of epochs.\n",
        "\n",
        "###for inputs, labels in train_loader:\n",
        "\n",
        "Loop over each batch of inputs and labels provided by the DataLoader.\n",
        "Data Preparation:\n",
        "\n",
        "###inputs = inputs.float()\n",
        "\n",
        "Convert inputs to floating point numbers (if they are not already).\n",
        "\n",
        "###labels = labels.float()\n",
        "\n",
        "Convert labels to floating point numbers (if they are not already).\n",
        "\n",
        "-----\n",
        "##Feed Forward\n",
        "\n",
        "###output = net(inputs)\n",
        "\n",
        "Pass the inputs through the network to get the predicted outputs.\n",
        "Loss Calculation:\n",
        "\n",
        "###loss = criterion(output, labels)\n",
        "\n",
        "Calculate the loss using the criterion (loss function), which compares the predicted outputs with the actual labels.\n",
        "\n",
        "-----\n",
        "##Clear Gradient Buffer\n",
        "\n",
        "###optimizer.zero_grad()\n",
        "\n",
        "Clear the gradients of all optimized tensors.\n",
        "\n",
        "This is important because gradients by default add up; we don't want to accumulate gradients from multiple forward passes.\n",
        "\n",
        "-----\n",
        "##Backpropagation\n",
        "\n",
        "###loss.backward()\n",
        "\n",
        "Compute the gradient of the loss with respect to the network's parameters (i.e., perform backpropagation).\n",
        "\n",
        "##Weight Update\n",
        "\n",
        "##optimizer.step()\n",
        "\n",
        "Update the network's parameters based on the gradients computed during backpropagation.\n",
        "-----\n",
        "##Accuracy Calculation (at the end of each epoch):\n",
        "\n",
        "###output = (output > 0.5).float()\n",
        "\n",
        "Apply thresholding to the output to convert probabilities to binary predictions (since we're likely dealing with a binary classification problem).\n",
        "\n",
        "###accuracy = (output == labels).float().mean()\n",
        "\n",
        "Calculate the accuracy by comparing the thresholded output with the actual labels.\n",
        "\n",
        "------\n",
        "##Print Statistics\n",
        "\n",
        "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1, num_epochs, loss, accuracy))\n",
        "\n",
        "Print the current epoch number, loss, and accuracy.\n",
        "\n",
        "------\n",
        "#Summary\n",
        "The code snippet runs a training loop for a specified number of epochs.\n",
        "In each epoch, it processes batches of data, performs a forward pass, computes the loss, performs backpropagation, and updates the model parameters.\n",
        "\n",
        "It calculates and prints the loss and accuracy at the end of each epoch.\n",
        "This process helps to iteratively train the model and improve its performance on the training data.\n",
        "\n",
        "If you have any specific questions about any part of the code or its functionality, feel free to ask!"
      ],
      "metadata": {
        "id": "PVVZVr4IWZHS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gklya7WLSUB3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}